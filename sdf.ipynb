{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 complete\n",
      "loss: tf.Tensor(1.1377099, shape=(), dtype=float32) d_loss:  tf.Tensor(0.6184919, shape=(), dtype=float32)\n",
      "condition  Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 complete\n",
      "loss: tf.Tensor(4.6402693, shape=(), dtype=float32) d_loss:  tf.Tensor(0.019769674, shape=(), dtype=float32)\n",
      "condition  Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 complete\n",
      "loss: tf.Tensor(6.433007, shape=(), dtype=float32) d_loss:  tf.Tensor(0.004424053, shape=(), dtype=float32)\n",
      "condition  Dress\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\jupyter\\sdf.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 175>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=170'>171</a>\u001b[0m         plt\u001b[39m.\u001b[39mimshow(tf\u001b[39m.\u001b[39msqueeze(generated)\u001b[39m.\u001b[39mnumpy(), cmap\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgray\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=171'>172</a>\u001b[0m         plt\u001b[39m.\u001b[39mshow()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=174'>175</a>\u001b[0m train()\n",
      "\u001b[1;32mc:\\jupyter\\sdf.ipynb Cell 1'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=158'>159</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=159'>160</a>\u001b[0m     \u001b[39mfor\u001b[39;00m image, label \u001b[39min\u001b[39;00m dataset:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=160'>161</a>\u001b[0m         g_loss_value, d_loss_value, generated, condition \u001b[39m=\u001b[39m train_step(image, label)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=162'>163</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mepoch \u001b[39m\u001b[39m\"\u001b[39m, epoch, \u001b[39m\"\u001b[39m\u001b[39mcomplete\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/jupyter/sdf.ipynb#ch0000000?line=163'>164</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mloss:\u001b[39m\u001b[39m\"\u001b[39m, g_loss_value, \u001b[39m\"\u001b[39m\u001b[39md_loss: \u001b[39m\u001b[39m\"\u001b[39m, d_loss_value)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:910\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    907\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    909\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 910\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    912\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    913\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:942\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    939\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    940\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    941\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    944\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    945\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3130\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3128\u001b[0m   (graph_function,\n\u001b[0;32m   3129\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3131\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1959\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1955\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1956\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1957\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1958\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1959\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1960\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1961\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1962\u001b[0m     args,\n\u001b[0;32m   1963\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1964\u001b[0m     executing_eagerly)\n\u001b[0;32m   1965\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:598\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    597\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    601\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    602\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    604\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    606\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    607\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    610\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    611\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\mibot\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:58\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     57\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 58\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     59\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     61\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "dataset, info = tfds.load(\"fashion_mnist\", split=\"train\", with_info=True)\n",
    "\n",
    "\n",
    "def convert(row):\n",
    "    image = tf.image.convert_image_dtype(row[\"image\"], tf.float32)\n",
    "    label = tf.expand_dims(tf.cast(row[\"label\"], tf.float32), axis=-1)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "dataset = dataset.map(convert).batch(batch_size).prefetch(1)\n",
    "\n",
    "\n",
    "def get_generator(latent_dimension):\n",
    "\n",
    "    # Condition subnetwork: encode the condition in a hidden representation\n",
    "    condition = tf.keras.layers.Input((1,))\n",
    "    net = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n",
    "    net = tf.keras.layers.Dense(64, activation=tf.nn.elu)(net)\n",
    "\n",
    "    # Concatenate the hidden condition representation to noise and upsample\n",
    "    noise = tf.keras.layers.Input(latent_dimension)\n",
    "    inputs = tf.keras.layers.Concatenate()([noise, net])\n",
    "\n",
    "    # Convert inputs from (batch_size, latent_dimension + 1)\n",
    "    # To a 4-D tensor, that can be used with convolutions\n",
    "    inputs = tf.keras.layers.Reshape((1, 1, inputs.shape[-1]))(inputs)\n",
    "\n",
    "    depth = 128\n",
    "    kernel_size = 5\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth, kernel_size, padding=\"valid\", strides=1, activation=tf.nn.relu\n",
    "    )(\n",
    "        inputs\n",
    "    )  # 5x5\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth // 2, kernel_size, padding=\"valid\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        net\n",
    "    )  # 13x13\n",
    "    net = tf.keras.layers.Conv2DTranspose(\n",
    "        depth // 4,\n",
    "        kernel_size,\n",
    "        padding=\"valid\",\n",
    "        strides=2,\n",
    "        activation=tf.nn.relu,\n",
    "        use_bias=False,\n",
    "    )(\n",
    "        net\n",
    "    )  # 29x29\n",
    "    # Standard convolution with a 2x2 kernel to obtain a 28x28x1 out\n",
    "    # The output is a sigmoid, since the images are in the [0,1] range\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        1, 2, padding=\"valid\", strides=1, activation=tf.nn.sigmoid, use_bias=False\n",
    "    )(net)\n",
    "    model = tf.keras.Model(inputs=[noise, condition], outputs=net)\n",
    "    return model\n",
    "\n",
    "\n",
    "latent_dimension = 100\n",
    "G = get_generator(latent_dimension)\n",
    "\n",
    "\n",
    "def get_discriminator():\n",
    "    # Encoder subnetwork: feature extactor to get a feature vector\n",
    "    image = tf.keras.layers.Input((28, 28, 1))\n",
    "    depth = 32\n",
    "    kernel_size = 3\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth, kernel_size, padding=\"same\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        image\n",
    "    )  # 14x14x32\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth * 2, kernel_size, padding=\"same\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        net\n",
    "    )  # 7x7x64\n",
    "\n",
    "    net = tf.keras.layers.Conv2D(\n",
    "        depth * 3, kernel_size, padding=\"same\", strides=2, activation=tf.nn.relu\n",
    "    )(\n",
    "        net\n",
    "    )  # 4x4x96\n",
    "\n",
    "    feature_vector = tf.keras.layers.Flatten()(net)  # 4*4*96\n",
    "\n",
    "    # Create a hidden representation of the condition\n",
    "    condition = tf.keras.layers.Input((1,))\n",
    "    hidden = tf.keras.layers.Dense(32, activation=tf.nn.elu)(condition)\n",
    "    hidden = tf.keras.layers.Dense(64, activation=tf.nn.elu)(hidden)\n",
    "\n",
    "    # Concatenate the feature vector and the hidden label representatio\n",
    "    out = tf.keras.layers.Concatenate()([feature_vector, hidden])\n",
    "\n",
    "    # Add the final classification layers with a single linear neuron\n",
    "    out = tf.keras.layers.Dense(128, activation=tf.nn.relu)(out)\n",
    "    out = tf.keras.layers.Dense(1)(out)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[image, condition], outputs=out)\n",
    "    return model\n",
    "\n",
    "\n",
    "D = get_discriminator()\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "\n",
    "def d_loss(d_real, d_fake):\n",
    "    \"\"\"The disciminator loss function.\"\"\"\n",
    "    return bce(tf.ones_like(d_real), d_real) + bce(tf.zeros_like(d_fake), d_fake)\n",
    "\n",
    "\n",
    "def g_loss(generated_output):\n",
    "    \"\"\"The Generator loss function.\"\"\"\n",
    "    return bce(tf.ones_like(generated_output), generated_output)\n",
    "\n",
    "\n",
    "# Commented out IPython magic to ensure Python compatibility.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "def train():\n",
    "    # Define the optimizers and the train operations\n",
    "    optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(image, label):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            noise_vector = tf.random.normal(\n",
    "                mean=0, stddev=1, shape=(image.shape[0], latent_dimension)\n",
    "            )\n",
    "            # Sample from the Generator\n",
    "            fake_data = G([noise_vector, label])\n",
    "            # Compute the D loss\n",
    "            d_fake_data = D([fake_data, label])\n",
    "            d_real_data = D([image, label])\n",
    "\n",
    "            d_loss_value = d_loss(d_real_data, d_fake_data)\n",
    "            # Compute the G loss\n",
    "            g_loss_value = g_loss(d_fake_data)\n",
    "        # Now that we comptuted the losses we can compute the gradient (using the tape)\n",
    "        # and optimize the networks\n",
    "        d_gradients = tape.gradient(d_loss_value, D.trainable_variables)\n",
    "        g_gradients = tape.gradient(g_loss_value, G.trainable_variables)\n",
    "        # Deletng the tape, since we defined it as persistent (because we used it twice)\n",
    "        del tape\n",
    "\n",
    "        optimizer.apply_gradients(zip(d_gradients, D.trainable_variables))\n",
    "        optimizer.apply_gradients(zip(g_gradients, G.trainable_variables))\n",
    "        return g_loss_value, d_loss_value, fake_data[0], label[0]\n",
    "\n",
    "    epochs = 50\n",
    "    for epoch in range(epochs):\n",
    "        for image, label in dataset:\n",
    "            g_loss_value, d_loss_value, generated, condition = train_step(image, label)\n",
    "\n",
    "        print(\"epoch \", epoch, \"complete\")\n",
    "        print(\"loss:\", g_loss_value, \"d_loss: \", d_loss_value)\n",
    "        print(\n",
    "            \"condition \",\n",
    "            info.features[\"label\"].int2str(\n",
    "                tf.squeeze(tf.cast(condition, tf.int32)).numpy()\n",
    "            ),\n",
    "        )\n",
    "        plt.imshow(tf.squeeze(generated).numpy(), cmap=\"gray\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mibot')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e3d47cc14d0a7d841567c666b1bce259a39d7b78ffe0f6911e5c2094b850179"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
